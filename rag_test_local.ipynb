{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import glob\n",
    "\n",
    "import faiss\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ],
   "id": "672cee5aeea4c65d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load models",
   "id": "9bdd945c1c3aa0af"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "llm = LlamaCpp(\n",
    "    model_path=\"models/Llama-3.2-3B-Instruct-Q6_K_L.gguf\",\n",
    "    n_gpu_layers=-1, # Set to 0 for only cpu\n",
    "    n_ctx=1024,\n",
    "    temperature=0\n",
    ")\n",
    "embeddings_model = LlamaCppEmbeddings(\n",
    "    model_path=\"models/mxbai-embed-large-v1.Q8_0.gguf\", \n",
    "    n_gpu_layers=-1 # Set to 0 for only cpu\n",
    ")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load test pdf files",
   "id": "57ec22ecdd61a486"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pdf_paths = glob.glob(\"test-data/*.pdf\")\n",
    "\n",
    "pages = []\n",
    "\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)"
   ],
   "id": "887d0afea8948e0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load test txt files",
   "id": "9248919e52f0f0a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loader = DirectoryLoader(path=\"test-data\", glob=\"*.txt\", loader_cls=TextLoader)\n",
    "pages = pages + loader.load()"
   ],
   "id": "c72d2745d02c2de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split data in chunks",
   "id": "52b75d8319b986a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(pages)"
   ],
   "id": "47ffb6228e2a1a95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate embeddings and save them in vector store",
   "id": "fb323eb8570c40f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "index = faiss.IndexFlatL2(len(embeddings_model.embed_query(\"hello world\")))  #Get dimensions of embeddings\n",
    "\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(documents=splits)\n",
    "\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ],
   "id": "9e0b35e3a39ce03c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Make RAG request",
   "id": "7d77c5043db85290"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise. Answer only with the information and not with any kind of chat!\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "question = \"Warum sollte ich Daten kapseln?\"\n",
    "\n",
    "answer = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "print(f\"Frage: {answer['input']}\")\n",
    "print(f\"Antwort: {answer['answer']}\")\n",
    "print()\n",
    "print(\"Quellen:\")\n",
    "for source in answer[\"context\"]:\n",
    "    print(f\"\\t{source.metadata['source']} - Seite: {source.metadata['page']}\")"
   ],
   "id": "c790992d1478c76",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
